[2024-09-22 23:04:26.717] [info] rag_api_server in src/main.rs:154: server_version: 0.9.4
[2024-09-22 23:04:26.718] [info] rag_api_server in src/main.rs:162: model_name: Qwen1.5-1.8B-Chat-Q5_K_M,nomic-embed-text-v1.5.f16
[2024-09-22 23:04:26.718] [info] rag_api_server in src/main.rs:170: model_alias: default,embedding
[2024-09-22 23:04:26.718] [info] rag_api_server in src/main.rs:184: ctx_size: 4096,8192
[2024-09-22 23:04:26.718] [info] rag_api_server in src/main.rs:198: batch_size: 4096,8192
[2024-09-22 23:04:26.718] [info] rag_api_server in src/main.rs:212: prompt_template: chatml,embedding
[2024-09-22 23:04:26.718] [info] rag_api_server in src/main.rs:220: n_predict: 1024
[2024-09-22 23:04:26.718] [info] rag_api_server in src/main.rs:223: n_gpu_layers: 100
[2024-09-22 23:04:26.718] [info] rag_api_server in src/main.rs:236: threads: 2
[2024-09-22 23:04:26.718] [info] rag_api_server in src/main.rs:250: rag_prompt: The following text is the context for the user question.\n----------------\n
[2024-09-22 23:04:26.719] [info] rag_api_server in src/main.rs:271: qdrant_url: http://127.0.0.1:6333
[2024-09-22 23:04:26.719] [info] rag_api_server in src/main.rs:274: qdrant_collection_name: default
[2024-09-22 23:04:26.719] [info] rag_api_server in src/main.rs:277: qdrant_limit: 3
[2024-09-22 23:04:26.719] [info] rag_api_server in src/main.rs:280: qdrant_score_threshold: 0.5
[2024-09-22 23:04:26.719] [info] rag_api_server in src/main.rs:291: chunk_capacity: 100
[2024-09-22 23:04:26.719] [info] rag_api_server in src/main.rs:294: rag_policy: system-message
[2024-09-22 23:04:26.719] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:434: Initializing the core context for RAG scenarios
[2024-09-22 23:04:26.723] [info] [WASI-NN] GGML backend: LLAMA_COMMIT 8f1d81a0
[2024-09-22 23:04:26.723] [info] [WASI-NN] GGML backend: LLAMA_BUILD_NUMBER 3651
[2024-09-22 23:04:26.768] [info] [WASI-NN] llama.cpp: llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from Qwen1.5-1.8B-Chat-Q5_K_M.gguf (version GGUF V3 (latest))
[2024-09-22 23:04:26.768] [info] [WASI-NN] llama.cpp: llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
[2024-09-22 23:04:26.768] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   0:                       general.architecture str              = qwen2
[2024-09-22 23:04:26.768] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   1:                               general.name str              = Qwen1.5-1.8B-Chat
[2024-09-22 23:04:26.768] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   2:                          qwen2.block_count u32              = 24
[2024-09-22 23:04:26.768] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   3:                       qwen2.context_length u32              = 32768
[2024-09-22 23:04:26.768] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   4:                     qwen2.embedding_length u32              = 2048
[2024-09-22 23:04:26.768] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   5:                  qwen2.feed_forward_length u32              = 5504
[2024-09-22 23:04:26.768] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   6:                 qwen2.attention.head_count u32              = 16
[2024-09-22 23:04:26.768] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   7:              qwen2.attention.head_count_kv u32              = 16
[2024-09-22 23:04:26.769] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   8:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001
[2024-09-22 23:04:26.769] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   9:                qwen2.use_parallel_residual bool             = true
[2024-09-22 23:04:26.769] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  10:                       tokenizer.ggml.model str              = gpt2
[2024-09-22 23:04:26.787] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  11:                      tokenizer.ggml.tokens arr[str,151936]  = ["!", "\"", "#", "$", "%", "&", "'", ...
[2024-09-22 23:04:26.797] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  12:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  13:                      tokenizer.ggml.merges arr[str,151387]  = ["Ġ Ġ", "ĠĠ ĠĠ", "i n", "Ġ t",...
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  14:                tokenizer.ggml.eos_token_id u32              = 151643
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  15:            tokenizer.ggml.padding_token_id u32              = 151643
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 151643
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  17:                    tokenizer.chat_template str              = {% for message in messages %}{{'<|im_...
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  18:               general.quantization_version u32              = 2
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  19:                          general.file_type u32              = 17
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - type  f32:  121 tensors
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - type q5_1:   12 tensors
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - type q8_0:   12 tensors
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - type q5_K:  133 tensors
[2024-09-22 23:04:26.815] [info] [WASI-NN] llama.cpp: llama_model_loader: - type q6_K:   13 tensors
[2024-09-22 23:04:26.914] [warning] [WASI-NN] llama.cpp: llm_load_vocab: missing pre-tokenizer type, using: 'default'
[2024-09-22 23:04:26.914] [warning] [WASI-NN] llama.cpp: llm_load_vocab:                                             
[2024-09-22 23:04:26.914] [warning] [WASI-NN] llama.cpp: llm_load_vocab: ************************************        
[2024-09-22 23:04:26.914] [warning] [WASI-NN] llama.cpp: llm_load_vocab: GENERATION QUALITY WILL BE DEGRADED!        
[2024-09-22 23:04:26.914] [warning] [WASI-NN] llama.cpp: llm_load_vocab: CONSIDER REGENERATING THE MODEL             
[2024-09-22 23:04:26.914] [warning] [WASI-NN] llama.cpp: llm_load_vocab: ************************************        
[2024-09-22 23:04:26.914] [warning] [WASI-NN] llama.cpp: llm_load_vocab:                                             
[2024-09-22 23:04:26.981] [info] [WASI-NN] llama.cpp: llm_load_vocab: special tokens cache size = 293
[2024-09-22 23:04:27.015] [info] [WASI-NN] llama.cpp: llm_load_vocab: token to piece cache size = 0.9338 MB
[2024-09-22 23:04:27.015] [info] [WASI-NN] llama.cpp: llm_load_print_meta: format           = GGUF V3 (latest)
[2024-09-22 23:04:27.015] [info] [WASI-NN] llama.cpp: llm_load_print_meta: arch             = qwen2
[2024-09-22 23:04:27.015] [info] [WASI-NN] llama.cpp: llm_load_print_meta: vocab type       = BPE
[2024-09-22 23:04:27.015] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_vocab          = 151936
[2024-09-22 23:04:27.015] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_merges         = 151387
[2024-09-22 23:04:27.015] [info] [WASI-NN] llama.cpp: llm_load_print_meta: vocab_only       = 0
[2024-09-22 23:04:27.015] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_ctx_train      = 32768
[2024-09-22 23:04:27.015] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_embd           = 2048
[2024-09-22 23:04:27.015] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_layer          = 24
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_head           = 16
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_head_kv        = 16
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_rot            = 128
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_swa            = 0
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_embd_head_k    = 128
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_embd_head_v    = 128
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_gqa            = 1
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_embd_k_gqa     = 2048
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_embd_v_gqa     = 2048
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: f_norm_eps       = 0.0e+00
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: f_norm_rms_eps   = 1.0e-06
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: f_clamp_kqv      = 0.0e+00
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: f_max_alibi_bias = 0.0e+00
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: f_logit_scale    = 0.0e+00
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_ff             = 5504
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_expert         = 0
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_expert_used    = 0
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: causal attn      = 1
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: pooling type     = 0
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: rope type        = 2
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: rope scaling     = linear
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: freq_base_train  = 10000.0
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: freq_scale_train = 1
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_ctx_orig_yarn  = 32768
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: rope_finetuned   = unknown
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: ssm_d_conv       = 0
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: ssm_d_inner      = 0
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: ssm_d_state      = 0
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: ssm_dt_rank      = 0
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: ssm_dt_b_c_rms   = 0
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: model type       = 1B
[2024-09-22 23:04:27.016] [info] [WASI-NN] llama.cpp: llm_load_print_meta: model ftype      = Q5_K - Medium
[2024-09-22 23:04:27.017] [info] [WASI-NN] llama.cpp: llm_load_print_meta: model params     = 1.84 B
[2024-09-22 23:04:27.017] [info] [WASI-NN] llama.cpp: llm_load_print_meta: model size       = 1.28 GiB (5.97 BPW) 
[2024-09-22 23:04:27.017] [info] [WASI-NN] llama.cpp: llm_load_print_meta: general.name     = Qwen1.5-1.8B-Chat
[2024-09-22 23:04:27.017] [info] [WASI-NN] llama.cpp: llm_load_print_meta: BOS token        = 151643 '<|endoftext|>'
[2024-09-22 23:04:27.017] [info] [WASI-NN] llama.cpp: llm_load_print_meta: EOS token        = 151643 '<|endoftext|>'
[2024-09-22 23:04:27.017] [info] [WASI-NN] llama.cpp: llm_load_print_meta: PAD token        = 151643 '<|endoftext|>'
[2024-09-22 23:04:27.017] [info] [WASI-NN] llama.cpp: llm_load_print_meta: LF token         = 148848 'ÄĬ'
[2024-09-22 23:04:27.017] [info] [WASI-NN] llama.cpp: llm_load_print_meta: EOT token        = 151645 '<|im_end|>'
[2024-09-22 23:04:27.017] [info] [WASI-NN] llama.cpp: llm_load_print_meta: max token length = 256
[2024-09-22 23:04:27.017] [info] [WASI-NN] llama.cpp: llm_load_tensors: ggml ctx size =    0.13 MiB
[2024-09-22 23:04:27.061] [info] [WASI-NN] llama.cpp: llm_load_tensors:        CPU buffer size =  1307.33 MiB
[2024-09-22 23:04:27.062] [info] [WASI-NN] llama.cpp: 
[2024-09-22 23:04:27.069] [info] [WASI-NN] GGML backend: llama_system_info: AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | 
[2024-09-22 23:04:27.069] [info] [WASI-NN] GGML backend: LLAMA_COMMIT 8f1d81a0
[2024-09-22 23:04:27.069] [info] [WASI-NN] GGML backend: LLAMA_BUILD_NUMBER 3651
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: loaded meta data with 22 key-value pairs and 112 tensors from nomic-embed-text-v1.5.f16.gguf (version GGUF V3 (latest))
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   0:                       general.architecture str              = nomic-bert
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   1:                               general.name str              = nomic-embed-text-v1.5
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   2:                     nomic-bert.block_count u32              = 12
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   3:                  nomic-bert.context_length u32              = 2048
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   4:                nomic-bert.embedding_length u32              = 768
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   5:             nomic-bert.feed_forward_length u32              = 3072
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   6:            nomic-bert.attention.head_count u32              = 12
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   7:    nomic-bert.attention.layer_norm_epsilon f32              = 0.000000
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   8:                          general.file_type u32              = 1
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv   9:                nomic-bert.attention.causal bool             = false
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  10:                    nomic-bert.pooling_type u32              = 1
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  11:                  nomic-bert.rope.freq_base f32              = 1000.000000
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  12:            tokenizer.ggml.token_type_count u32              = 2
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  13:                tokenizer.ggml.bos_token_id u32              = 101
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  14:                tokenizer.ggml.eos_token_id u32              = 102
[2024-09-22 23:04:27.074] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = bert
[2024-09-22 23:04:27.077] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  16:                      tokenizer.ggml.tokens arr[str,30522]   = ["[PAD]", "[unused0]", "[unused1]", "...
[2024-09-22 23:04:27.084] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  17:                      tokenizer.ggml.scores arr[f32,30522]   = [-1000.000000, -1000.000000, -1000.00...
[2024-09-22 23:04:27.086] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,30522]   = [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
[2024-09-22 23:04:27.086] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 100
[2024-09-22 23:04:27.086] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  20:          tokenizer.ggml.seperator_token_id u32              = 102
[2024-09-22 23:04:27.086] [info] [WASI-NN] llama.cpp: llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0
[2024-09-22 23:04:27.086] [info] [WASI-NN] llama.cpp: llama_model_loader: - type  f32:   51 tensors
[2024-09-22 23:04:27.086] [info] [WASI-NN] llama.cpp: llama_model_loader: - type  f16:   61 tensors
[2024-09-22 23:04:27.091] [info] [WASI-NN] llama.cpp: llm_load_vocab: special tokens cache size = 5
[2024-09-22 23:04:27.092] [info] [WASI-NN] llama.cpp: llm_load_vocab: token to piece cache size = 0.2032 MB
[2024-09-22 23:04:27.092] [info] [WASI-NN] llama.cpp: llm_load_print_meta: format           = GGUF V3 (latest)
[2024-09-22 23:04:27.092] [info] [WASI-NN] llama.cpp: llm_load_print_meta: arch             = nomic-bert
[2024-09-22 23:04:27.092] [info] [WASI-NN] llama.cpp: llm_load_print_meta: vocab type       = WPM
[2024-09-22 23:04:27.092] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_vocab          = 30522
[2024-09-22 23:04:27.092] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_merges         = 0
[2024-09-22 23:04:27.092] [info] [WASI-NN] llama.cpp: llm_load_print_meta: vocab_only       = 0
[2024-09-22 23:04:27.092] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_ctx_train      = 2048
[2024-09-22 23:04:27.092] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_embd           = 768
[2024-09-22 23:04:27.092] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_layer          = 12
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_head           = 12
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_head_kv        = 12
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_rot            = 64
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_swa            = 0
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_embd_head_k    = 64
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_embd_head_v    = 64
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_gqa            = 1
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_embd_k_gqa     = 768
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_embd_v_gqa     = 768
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: f_norm_eps       = 1.0e-12
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: f_norm_rms_eps   = 0.0e+00
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: f_clamp_kqv      = 0.0e+00
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: f_max_alibi_bias = 0.0e+00
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: f_logit_scale    = 0.0e+00
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_ff             = 3072
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_expert         = 0
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_expert_used    = 0
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: causal attn      = 0
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: pooling type     = 1
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: rope type        = 2
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: rope scaling     = linear
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: freq_base_train  = 1000.0
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: freq_scale_train = 1
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: n_ctx_orig_yarn  = 2048
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: rope_finetuned   = unknown
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: ssm_d_conv       = 0
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: ssm_d_inner      = 0
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: ssm_d_state      = 0
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: ssm_dt_rank      = 0
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: ssm_dt_b_c_rms   = 0
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: model type       = 137M
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: model ftype      = F16
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: model params     = 136.73 M
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: model size       = 260.86 MiB (16.00 BPW) 
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: general.name     = nomic-embed-text-v1.5
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: BOS token        = 101 '[CLS]'
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: EOS token        = 102 '[SEP]'
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: UNK token        = 100 '[UNK]'
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: SEP token        = 102 '[SEP]'
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: PAD token        = 0 '[PAD]'
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: CLS token        = 101 '[CLS]'
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: MASK token       = 103 '[MASK]'
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: LF token         = 0 '[PAD]'
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_print_meta: max token length = 21
[2024-09-22 23:04:27.093] [info] [WASI-NN] llama.cpp: llm_load_tensors: ggml ctx size =    0.05 MiB
[2024-09-22 23:04:27.099] [info] [WASI-NN] llama.cpp: llm_load_tensors:        CPU buffer size =   260.86 MiB
[2024-09-22 23:04:27.099] [info] [WASI-NN] llama.cpp: 
[2024-09-22 23:04:27.100] [info] [WASI-NN] GGML backend: llama_system_info: AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | 
[2024-09-22 23:04:27.100] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:489: running mode: rag
[2024-09-22 23:04:27.100] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:502: The core context for RAG scenarios has been initialized
[2024-09-22 23:04:27.100] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:512: Getting the plugin info
[2024-09-22 23:04:27.100] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:698: Get the running mode.
[2024-09-22 23:04:27.100] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:723: running mode: rag
[2024-09-22 23:04:27.101] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:592: Getting the plugin info by the graph named Qwen1.5-1.8B-Chat-Q5_K_M
[2024-09-22 23:04:27.101] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:169: Get the output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M
[2024-09-22 23:04:27.101] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:187: Output buffer size: 95
[2024-09-22 23:04:27.101] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:652: Plugin info: b3651(commit 8f1d81a0)
[2024-09-22 23:04:27.101] [info] rag_api_server in src/main.rs:404: plugin_ggml_version: b3651 (commit 8f1d81a0)
[2024-09-22 23:04:27.101] [info] rag_api_server in src/main.rs:414: socket_address: 0.0.0.0:8080
[2024-09-22 23:04:27.101] [info] rag_api_server in src/main.rs:421: gaianet_node_version: 0.4.2
[2024-09-22 23:04:38.496] [info] rag_api_server in src/main.rs:443: remote_addr: 0.0.0.0:51222, local_addr: 0.0.0.0:8080
[2024-09-22 23:04:38.497] [info] rag_api_server in src/main.rs:495: method: POST, http_version: HTTP/1.1, content-length: 99
[2024-09-22 23:04:38.497] [info] rag_api_server in src/main.rs:496: endpoint: /v1/chat/completions
[2024-09-22 23:04:38.497] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:189: Handling the coming rag query request
[2024-09-22 23:04:38.497] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:212: Prepare the chat completion request.
[2024-09-22 23:04:38.497] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:248: user: chatcmpl-5043a466-3f50-47af-ae25-f456d5981c99
[2024-09-22 23:04:38.497] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:262: Compute embeddings for user query.
[2024-09-22 23:04:38.497] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:291: query text: What is your name?
[2024-09-22 23:04:38.497] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:51: Get the names of the embedding models.
[2024-09-22 23:04:38.497] [info] llama_core::rag in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/rag.rs:98: Compute embeddings for the user query.
[2024-09-22 23:04:38.497] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:698: Get the running mode.
[2024-09-22 23:04:38.497] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:723: running mode: rag
[2024-09-22 23:04:38.497] [info] llama_core::embeddings in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/embeddings.rs:28: Computing embeddings
[2024-09-22 23:04:38.497] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:698: Get the running mode.
[2024-09-22 23:04:38.497] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:723: running mode: rag
[2024-09-22 23:04:38.497] [info] llama_core::graph in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/graph.rs:296: Update metadata for the model named nomic-embed-text-v1.5.f16
[2024-09-22 23:04:38.498] [info] llama_core::graph in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/graph.rs:314: Metadata updated successfully.
[2024-09-22 23:04:38.498] [info] llama_core::embeddings in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/embeddings.rs:133: Compute embeddings for 1 chunks
[2024-09-22 23:04:38.499] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ctx      = 8192
[2024-09-22 23:04:38.499] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_batch    = 512
[2024-09-22 23:04:38.499] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ubatch   = 512
[2024-09-22 23:04:38.499] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: flash_attn = 0
[2024-09-22 23:04:38.499] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_base  = 1000.0
[2024-09-22 23:04:38.499] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_scale = 1
[2024-09-22 23:04:38.597] [info] [WASI-NN] llama.cpp: llama_kv_cache_init:        CPU KV buffer size =   288.00 MiB
[2024-09-22 23:04:38.597] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: KV self size  =  288.00 MiB, K (f16):  144.00 MiB, V (f16):  144.00 MiB
[2024-09-22 23:04:38.598] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU  output buffer size =     0.00 MiB
[2024-09-22 23:04:38.603] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU compute buffer size =    23.00 MiB
[2024-09-22 23:04:38.603] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph nodes  = 453
[2024-09-22 23:04:38.603] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph splits = 1
[2024-09-22 23:04:38.604] [info] llama_core::embeddings in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/embeddings.rs:153: compute embeddings for chunk 1
[2024-09-22 23:04:38.605] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ctx      = 8192
[2024-09-22 23:04:38.605] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_batch    = 512
[2024-09-22 23:04:38.605] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ubatch   = 512
[2024-09-22 23:04:38.605] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: flash_attn = 0
[2024-09-22 23:04:38.605] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_base  = 1000.0
[2024-09-22 23:04:38.605] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_scale = 1
[2024-09-22 23:04:38.638] [info] [WASI-NN] llama.cpp: llama_kv_cache_init:        CPU KV buffer size =   288.00 MiB
[2024-09-22 23:04:38.638] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: KV self size  =  288.00 MiB, K (f16):  144.00 MiB, V (f16):  144.00 MiB
[2024-09-22 23:04:38.638] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU  output buffer size =     0.00 MiB
[2024-09-22 23:04:38.639] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU compute buffer size =    23.00 MiB
[2024-09-22 23:04:38.639] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph nodes  = 453
[2024-09-22 23:04:38.639] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph splits = 1
[2024-09-22 23:04:39.784] [info] [WASI-NN] llama.cpp: 
[2024-09-22 23:04:39.784] [info] [WASI-NN] llama.cpp: llama_print_timings:        load time =   12689.79 ms
[2024-09-22 23:04:39.784] [info] [WASI-NN] llama.cpp: llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)
[2024-09-22 23:04:39.784] [info] [WASI-NN] llama.cpp: llama_print_timings: prompt eval time =    1120.35 ms /     7 tokens (  160.05 ms per token,     6.25 tokens per second)
[2024-09-22 23:04:39.784] [info] [WASI-NN] llama.cpp: llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)
[2024-09-22 23:04:39.784] [info] [WASI-NN] llama.cpp: llama_print_timings:       total time =   12690.52 ms /     8 tokens
[2024-09-22 23:04:39.786] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:169: Get the output buffer generated by the model named nomic-embed-text-v1.5.f16
[2024-09-22 23:04:39.786] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:187: Output buffer size: 11281
[2024-09-22 23:04:39.790] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:243: Get token info from the model named nomic-embed-text-v1.5.f16.
[2024-09-22 23:04:39.790] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:169: Get the output buffer generated by the model named nomic-embed-text-v1.5.f16
[2024-09-22 23:04:39.790] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:187: Output buffer size: 95
[2024-09-22 23:04:39.790] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:282: prompt tokens: 7, completion tokens: 0
[2024-09-22 23:04:39.790] [info] llama_core::embeddings in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/embeddings.rs:211: token usage of embeddings: 7 prompt tokens, 0 comletion tokens
[2024-09-22 23:04:39.790] [info] llama_core::embeddings in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/embeddings.rs:123: Embeddings computed successfully.
[2024-09-22 23:04:39.790] [info] llama_core::rag in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/rag.rs:133: Retrieve context.
[2024-09-22 23:04:39.791] [info] llama_core::rag in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/rag.rs:135: qdrant_url: http://127.0.0.1:6333, qdrant_collection_name: default, limit: 3, score_threshold: 0.5
[2024-09-22 23:04:39.791] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:698: Get the running mode.
[2024-09-22 23:04:39.791] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:723: running mode: rag
[2024-09-22 23:04:39.791] [info] llama_core::rag in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/rag.rs:281: Search similar points from the qdrant instance.
[2024-09-22 23:04:39.825] [info] llama_core::rag in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/rag.rs:294: Number of similar points found: 0
[2024-09-22 23:04:39.825] [warning] rag_api_server::backend::ggml in src/backend/ggml.rs:436: No point retrieved (score < threshold 0.5)
[2024-09-22 23:04:39.825] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:45: tool choice: Some(None)
[2024-09-22 23:04:39.825] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:46: tools: None
[2024-09-22 23:04:39.825] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:47: stream mode: Some(false)
[2024-09-22 23:04:39.825] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:622: Processing chat completion request in non-stream mode.
[2024-09-22 23:04:39.825] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:698: Get the running mode.
[2024-09-22 23:04:39.825] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:723: running mode: rag
[2024-09-22 23:04:39.825] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:644: user: chatcmpl-5043a466-3f50-47af-ae25-f456d5981c99
[2024-09-22 23:04:39.825] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:1604: Check model metadata.
[2024-09-22 23:04:39.825] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2267: Get the model metadata.
[2024-09-22 23:04:39.825] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:1903: Build the chat prompt from the chat messages.
[2024-09-22 23:04:39.825] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2267: Get the model metadata.
[2024-09-22 23:04:39.825] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2201: Set prompt to the chat model named Qwen1.5-1.8B-Chat-Q5_K_M.
[2024-09-22 23:04:39.825] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ctx      = 4096
[2024-09-22 23:04:39.825] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_batch    = 4096
[2024-09-22 23:04:39.825] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ubatch   = 4096
[2024-09-22 23:04:39.825] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: flash_attn = 0
[2024-09-22 23:04:39.825] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_base  = 10000.0
[2024-09-22 23:04:39.825] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_scale = 1
[2024-09-22 23:04:40.136] [info] [WASI-NN] llama.cpp: llama_kv_cache_init:        CPU KV buffer size =   768.00 MiB
[2024-09-22 23:04:40.136] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: KV self size  =  768.00 MiB, K (f16):  384.00 MiB, V (f16):  384.00 MiB
[2024-09-22 23:04:40.136] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU  output buffer size =     0.58 MiB
[2024-09-22 23:04:40.137] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU compute buffer size =  2406.00 MiB
[2024-09-22 23:04:40.137] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph nodes  = 846
[2024-09-22 23:04:40.137] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph splits = 1
[2024-09-22 23:04:40.143] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:243: Get token info from the model named Qwen1.5-1.8B-Chat-Q5_K_M.
[2024-09-22 23:04:40.143] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:169: Get the output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M
[2024-09-22 23:04:40.143] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:187: Output buffer size: 96
[2024-09-22 23:04:40.144] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:282: prompt tokens: 25, completion tokens: 0
[2024-09-22 23:04:40.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:655: prompt:
<|im_start|>system
Answer as concisely as possible.<|im_end|>
<|im_start|>user
What is your name?<|im_end|>
<|im_start|>assistant
[2024-09-22 23:04:40.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:656: available_completion_tokens: 820
[2024-09-22 23:04:40.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:657: tool_use: false
[2024-09-22 23:04:40.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:1709: available_completion_tokens: 820, max_tokens from request: 1024, n_predict: 1024
[2024-09-22 23:04:40.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:1719: update n_predict from 1024 to 820
[2024-09-22 23:04:40.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2327: Update the model metadata.
[2024-09-22 23:04:40.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2201: Set prompt to the chat model named Qwen1.5-1.8B-Chat-Q5_K_M.
[2024-09-22 23:04:40.144] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ctx      = 4096
[2024-09-22 23:04:40.144] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_batch    = 4096
[2024-09-22 23:04:40.144] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ubatch   = 4096
[2024-09-22 23:04:40.144] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: flash_attn = 0
[2024-09-22 23:04:40.144] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_base  = 10000.0
[2024-09-22 23:04:40.144] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_scale = 1
[2024-09-22 23:04:40.229] [info] [WASI-NN] llama.cpp: llama_kv_cache_init:        CPU KV buffer size =   768.00 MiB
[2024-09-22 23:04:40.229] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: KV self size  =  768.00 MiB, K (f16):  384.00 MiB, V (f16):  384.00 MiB
[2024-09-22 23:04:40.229] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU  output buffer size =     0.58 MiB
[2024-09-22 23:04:40.231] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU compute buffer size =  2406.00 MiB
[2024-09-22 23:04:40.231] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph nodes  = 846
[2024-09-22 23:04:40.231] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph splits = 1
[2024-09-22 23:04:40.234] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:681: Compute chat completion.
[2024-09-22 23:04:40.234] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:742: Compute chat completion by the model named Qwen1.5-1.8B-Chat-Q5_K_M.
[2024-09-22 23:04:40.235] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ctx      = 4096
[2024-09-22 23:04:40.235] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_batch    = 4096
[2024-09-22 23:04:40.235] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ubatch   = 4096
[2024-09-22 23:04:40.235] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: flash_attn = 0
[2024-09-22 23:04:40.235] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_base  = 10000.0
[2024-09-22 23:04:40.235] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_scale = 1
[2024-09-22 23:04:40.325] [info] [WASI-NN] llama.cpp: llama_kv_cache_init:        CPU KV buffer size =   768.00 MiB
[2024-09-22 23:04:40.325] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: KV self size  =  768.00 MiB, K (f16):  384.00 MiB, V (f16):  384.00 MiB
[2024-09-22 23:04:40.325] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU  output buffer size =     0.58 MiB
[2024-09-22 23:04:40.325] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU compute buffer size =  2406.00 MiB
[2024-09-22 23:04:40.325] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph nodes  = 846
[2024-09-22 23:04:40.325] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph splits = 1
[2024-09-22 23:04:55.163] [info] [WASI-NN] GGML backend: EOS token found
[2024-09-22 23:04:55.164] [info] [WASI-NN] llama.cpp: 
[2024-09-22 23:04:55.164] [info] [WASI-NN] llama.cpp: llama_print_timings:        load time =   24670.30 ms
[2024-09-22 23:04:55.164] [info] [WASI-NN] llama.cpp: llama_print_timings:      sample time =      28.74 ms /    37 runs   (    0.78 ms per token,  1287.54 tokens per second)
[2024-09-22 23:04:55.164] [info] [WASI-NN] llama.cpp: llama_print_timings: prompt eval time =   11360.00 ms /    25 tokens (  454.40 ms per token,     2.20 tokens per second)
[2024-09-22 23:04:55.164] [info] [WASI-NN] llama.cpp: llama_print_timings:        eval time =    3351.86 ms /    36 runs   (   93.11 ms per token,    10.74 tokens per second)
[2024-09-22 23:04:55.164] [info] [WASI-NN] llama.cpp: llama_print_timings:       total time =   28146.42 ms /    61 tokens
[2024-09-22 23:04:55.221] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:169: Get the output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M
[2024-09-22 23:04:55.221] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:187: Output buffer size: 185
[2024-09-22 23:04:55.221] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:761: raw generation: I'm QianWen, a large language model created by Alibaba Cloud. My primary function is to assist users in generating human-like text based on various prompts or inputs provided.<|im_end|>
[2024-09-22 23:04:55.221] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:1753: Post-process the generated output.
[2024-09-22 23:04:55.223] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:769: post-processed generation:
I'm QianWen, a large language model created by Alibaba Cloud. My primary function is to assist users in generating human-like text based on various prompts or inputs provided.
[2024-09-22 23:04:55.223] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:243: Get token info from the model named Qwen1.5-1.8B-Chat-Q5_K_M.
[2024-09-22 23:04:55.223] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:169: Get the output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M
[2024-09-22 23:04:55.223] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:187: Output buffer size: 97
[2024-09-22 23:04:55.223] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:282: prompt tokens: 25, completion tokens: 37
[2024-09-22 23:04:55.223] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:775: prompt tokens: 25, completion tokens: 37
[2024-09-22 23:04:55.224] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:670: End of the chat completion.
[2024-09-22 23:04:55.227] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:502: Finish chat completions in non-stream mode
[2024-09-22 23:04:55.227] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:529: Send the rag query response
[2024-09-22 23:04:55.228] [info] rag_api_server in src/main.rs:515: response_version: HTTP/1.1
[2024-09-22 23:04:55.229] [info] rag_api_server in src/main.rs:517: response_body_size: 489
[2024-09-22 23:04:55.229] [info] rag_api_server in src/main.rs:519: response_status: 200
[2024-09-22 23:04:55.229] [info] rag_api_server in src/main.rs:521: response_is_success: true
[2024-09-22 23:05:16.599] [info] rag_api_server in src/main.rs:443: remote_addr: 0.0.0.0:37420, local_addr: 0.0.0.0:8080
[2024-09-22 23:05:16.604] [info] rag_api_server in src/main.rs:498: method: GET, http_version: HTTP/1.1
[2024-09-22 23:05:16.604] [info] rag_api_server in src/main.rs:499: endpoint: /config_pub.json
[2024-09-22 23:05:16.615] [info] rag_api_server in src/main.rs:515: response_version: HTTP/1.1
[2024-09-22 23:05:16.615] [info] rag_api_server in src/main.rs:517: response_body_size: 1137
[2024-09-22 23:05:16.615] [info] rag_api_server in src/main.rs:519: response_status: 200
[2024-09-22 23:05:16.615] [info] rag_api_server in src/main.rs:521: response_is_success: true
[2024-09-22 23:05:26.768] [info] rag_api_server in src/main.rs:498: method: GET, http_version: HTTP/1.1
[2024-09-22 23:05:26.768] [info] rag_api_server in src/main.rs:499: endpoint: /v1/info
[2024-09-22 23:05:26.768] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:1677: Handling the coming server info request.
[2024-09-22 23:05:26.769] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:1724: Send the server info response.
[2024-09-22 23:05:26.769] [info] rag_api_server in src/main.rs:515: response_version: HTTP/1.1
[2024-09-22 23:05:26.769] [info] rag_api_server in src/main.rs:517: response_body_size: 810
[2024-09-22 23:05:26.769] [info] rag_api_server in src/main.rs:519: response_status: 200
[2024-09-22 23:05:26.769] [info] rag_api_server in src/main.rs:521: response_is_success: true
[2024-09-22 23:05:36.620] [info] rag_api_server in src/main.rs:498: method: OPTIONS, http_version: HTTP/1.1
[2024-09-22 23:05:36.620] [info] rag_api_server in src/main.rs:499: endpoint: /v1/chat/completions
[2024-09-22 23:05:36.620] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:189: Handling the coming rag query request
[2024-09-22 23:05:36.620] [info] rag_api_server in src/main.rs:515: response_version: HTTP/1.1
[2024-09-22 23:05:36.620] [info] rag_api_server in src/main.rs:517: response_body_size: 0
[2024-09-22 23:05:36.620] [info] rag_api_server in src/main.rs:519: response_status: 200
[2024-09-22 23:05:36.620] [info] rag_api_server in src/main.rs:521: response_is_success: true
[2024-09-22 23:05:37.183] [info] rag_api_server in src/main.rs:495: method: POST, http_version: HTTP/1.1, content-length: 325
[2024-09-22 23:05:37.183] [info] rag_api_server in src/main.rs:496: endpoint: /v1/chat/completions
[2024-09-22 23:05:37.183] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:189: Handling the coming rag query request
[2024-09-22 23:05:37.183] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:212: Prepare the chat completion request.
[2024-09-22 23:05:37.189] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:248: user: 9b619fe5-3a49-43fc-a8c4-6d939262f99f
[2024-09-22 23:05:37.189] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:262: Compute embeddings for user query.
[2024-09-22 23:05:37.189] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:291: query text: i am having stress and headache
[2024-09-22 23:05:37.189] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:51: Get the names of the embedding models.
[2024-09-22 23:05:37.190] [info] llama_core::rag in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/rag.rs:98: Compute embeddings for the user query.
[2024-09-22 23:05:37.190] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:698: Get the running mode.
[2024-09-22 23:05:37.190] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:723: running mode: rag
[2024-09-22 23:05:37.190] [info] llama_core::embeddings in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/embeddings.rs:28: Computing embeddings
[2024-09-22 23:05:37.190] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:698: Get the running mode.
[2024-09-22 23:05:37.190] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:723: running mode: rag
[2024-09-22 23:05:37.190] [info] llama_core::embeddings in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/embeddings.rs:133: Compute embeddings for 1 chunks
[2024-09-22 23:05:37.191] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ctx      = 8192
[2024-09-22 23:05:37.191] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_batch    = 512
[2024-09-22 23:05:37.191] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ubatch   = 512
[2024-09-22 23:05:37.191] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: flash_attn = 0
[2024-09-22 23:05:37.191] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_base  = 1000.0
[2024-09-22 23:05:37.191] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_scale = 1
[2024-09-22 23:05:37.310] [info] [WASI-NN] llama.cpp: llama_kv_cache_init:        CPU KV buffer size =   288.00 MiB
[2024-09-22 23:05:37.310] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: KV self size  =  288.00 MiB, K (f16):  144.00 MiB, V (f16):  144.00 MiB
[2024-09-22 23:05:37.310] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU  output buffer size =     0.00 MiB
[2024-09-22 23:05:37.324] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU compute buffer size =    23.00 MiB
[2024-09-22 23:05:37.324] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph nodes  = 453
[2024-09-22 23:05:37.324] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph splits = 1
[2024-09-22 23:05:37.352] [info] llama_core::embeddings in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/embeddings.rs:153: compute embeddings for chunk 1
[2024-09-22 23:05:37.352] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ctx      = 8192
[2024-09-22 23:05:37.352] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_batch    = 512
[2024-09-22 23:05:37.352] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ubatch   = 512
[2024-09-22 23:05:37.352] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: flash_attn = 0
[2024-09-22 23:05:37.352] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_base  = 1000.0
[2024-09-22 23:05:37.352] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_scale = 1
[2024-09-22 23:05:37.395] [info] [WASI-NN] llama.cpp: llama_kv_cache_init:        CPU KV buffer size =   288.00 MiB
[2024-09-22 23:05:37.395] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: KV self size  =  288.00 MiB, K (f16):  144.00 MiB, V (f16):  144.00 MiB
[2024-09-22 23:05:37.395] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU  output buffer size =     0.00 MiB
[2024-09-22 23:05:37.396] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU compute buffer size =    23.00 MiB
[2024-09-22 23:05:37.396] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph nodes  = 453
[2024-09-22 23:05:37.396] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph splits = 1
[2024-09-22 23:05:38.010] [info] [WASI-NN] llama.cpp: 
[2024-09-22 23:05:38.010] [info] [WASI-NN] llama.cpp: llama_print_timings:        load time =   70917.05 ms
[2024-09-22 23:05:38.010] [info] [WASI-NN] llama.cpp: llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)
[2024-09-22 23:05:38.010] [info] [WASI-NN] llama.cpp: llama_print_timings: prompt eval time =     593.48 ms /     8 tokens (   74.18 ms per token,    13.48 tokens per second)
[2024-09-22 23:05:38.010] [info] [WASI-NN] llama.cpp: llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)
[2024-09-22 23:05:38.010] [info] [WASI-NN] llama.cpp: llama_print_timings:       total time =   70917.52 ms /     9 tokens
[2024-09-22 23:05:38.012] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:169: Get the output buffer generated by the model named nomic-embed-text-v1.5.f16
[2024-09-22 23:05:38.012] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:187: Output buffer size: 11234
[2024-09-22 23:05:38.016] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:243: Get token info from the model named nomic-embed-text-v1.5.f16.
[2024-09-22 23:05:38.016] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:169: Get the output buffer generated by the model named nomic-embed-text-v1.5.f16
[2024-09-22 23:05:38.017] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:187: Output buffer size: 95
[2024-09-22 23:05:38.017] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:282: prompt tokens: 8, completion tokens: 0
[2024-09-22 23:05:38.017] [info] llama_core::embeddings in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/embeddings.rs:211: token usage of embeddings: 8 prompt tokens, 0 comletion tokens
[2024-09-22 23:05:38.017] [info] llama_core::embeddings in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/embeddings.rs:123: Embeddings computed successfully.
[2024-09-22 23:05:38.017] [info] llama_core::rag in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/rag.rs:133: Retrieve context.
[2024-09-22 23:05:38.018] [info] llama_core::rag in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/rag.rs:135: qdrant_url: http://127.0.0.1:6333, qdrant_collection_name: default, limit: 3, score_threshold: 0.5
[2024-09-22 23:05:38.018] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:698: Get the running mode.
[2024-09-22 23:05:38.018] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:723: running mode: rag
[2024-09-22 23:05:38.018] [info] llama_core::rag in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/rag.rs:281: Search similar points from the qdrant instance.
[2024-09-22 23:05:38.102] [info] llama_core::rag in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/rag.rs:294: Number of similar points found: 3
[2024-09-22 23:05:38.104] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:388: point: 0, score: 0.5855579, source: "User Input: \"How can I cope with stress?\"\nResponse: \"Here are a few strategies: deep breathing exercises, regular physical activity, and setting aside time for hobbies. What do you think would work for you?\"\n"
[2024-09-22 23:05:38.105] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:388: point: 1, score: 0.5769495, source: "User Input: \"I can't seem to shake off this sadness.\"\nResponse: \"Feeling sad can be tough. Have you experienced any changes in your routine or stressors that might be affecting your mood?\"\n"
[2024-09-22 23:05:38.105] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:388: point: 2, score: 0.57210577, source: "User Input: \"What are some signs I need help?\"\nResponse: \"If you're experiencing prolonged sadness, difficulty functioning in daily life, or thoughts of self-harm, it's important to seek help from a professional.\"\n"
[2024-09-22 23:05:38.105] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:87: Get the chat prompt template type from the chat model named Qwen1.5-1.8B-Chat-Q5_K_M.
[2024-09-22 23:05:38.106] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:122: prompt_template: chatml
[2024-09-22 23:05:38.106] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:567: rag_policy: system-message
[2024-09-22 23:05:38.107] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:571: context:
"User Input: \"How can I cope with stress?\"\nResponse: \"Here are a few strategies: deep breathing exercises, regular physical activity, and setting aside time for hobbies. What do you think would work for you?\"\n"

"User Input: \"I can't seem to shake off this sadness.\"\nResponse: \"Feeling sad can be tough. Have you experienced any changes in your routine or stressors that might be affecting your mood?\"\n"

"User Input: \"What are some signs I need help?\"\nResponse: \"If you're experiencing prolonged sadness, difficulty functioning in daily life, or thoughts of self-harm, it's important to seek help from a professional.\"\n"
[2024-09-22 23:05:38.107] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:575: Merge RAG context into system message.
[2024-09-22 23:05:38.107] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:45: tool choice: Some(None)
[2024-09-22 23:05:38.107] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:46: tools: None
[2024-09-22 23:05:38.108] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:47: stream mode: Some(true)
[2024-09-22 23:05:38.108] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:82: Process chat completion request in the stream mode.
[2024-09-22 23:05:38.108] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:698: Get the running mode.
[2024-09-22 23:05:38.108] [info] llama_core in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/lib.rs:723: running mode: rag
[2024-09-22 23:05:38.108] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:104: user: 9b619fe5-3a49-43fc-a8c4-6d939262f99f
[2024-09-22 23:05:38.108] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:113: include_usage: true
[2024-09-22 23:05:38.108] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:1604: Check model metadata.
[2024-09-22 23:05:38.108] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2267: Get the model metadata.
[2024-09-22 23:05:38.108] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:1903: Build the chat prompt from the chat messages.
[2024-09-22 23:05:38.108] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2267: Get the model metadata.
[2024-09-22 23:05:38.108] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2201: Set prompt to the chat model named Qwen1.5-1.8B-Chat-Q5_K_M.
[2024-09-22 23:05:38.108] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ctx      = 4096
[2024-09-22 23:05:38.108] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_batch    = 4096
[2024-09-22 23:05:38.108] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ubatch   = 4096
[2024-09-22 23:05:38.109] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: flash_attn = 0
[2024-09-22 23:05:38.109] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_base  = 10000.0
[2024-09-22 23:05:38.109] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_scale = 1
[2024-09-22 23:05:38.817] [info] [WASI-NN] llama.cpp: llama_kv_cache_init:        CPU KV buffer size =   768.00 MiB
[2024-09-22 23:05:38.817] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: KV self size  =  768.00 MiB, K (f16):  384.00 MiB, V (f16):  384.00 MiB
[2024-09-22 23:05:38.817] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU  output buffer size =     0.58 MiB
[2024-09-22 23:05:38.836] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU compute buffer size =  2406.00 MiB
[2024-09-22 23:05:38.836] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph nodes  = 846
[2024-09-22 23:05:38.836] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph splits = 1
[2024-09-22 23:05:40.638] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:243: Get token info from the model named Qwen1.5-1.8B-Chat-Q5_K_M.
[2024-09-22 23:05:40.638] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:169: Get the output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M
[2024-09-22 23:05:40.638] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:187: Output buffer size: 98
[2024-09-22 23:05:40.638] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:282: prompt tokens: 212, completion tokens: 37
[2024-09-22 23:05:40.638] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:124: prompt:
<|im_start|>system
You are a Mental Health expert. Please answer the question from a patient accurately.
The following text is the context for the user question.\n----------------\n
"User Input: \"How can I cope with stress?\"\nResponse: \"Here are a few strategies: deep breathing exercises, regular physical activity, and setting aside time for hobbies. What do you think would work for you?\"\n"

"User Input: \"I can't seem to shake off this sadness.\"\nResponse: \"Feeling sad can be tough. Have you experienced any changes in your routine or stressors that might be affecting your mood?\"\n"

"User Input: \"What are some signs I need help?\"\nResponse: \"If you're experiencing prolonged sadness, difficulty functioning in daily life, or thoughts of self-harm, it's important to seek help from a professional.\"\n"<|im_end|>
<|im_start|>user
i am having stress and headache<|im_end|>
<|im_start|>assistant
[2024-09-22 23:05:40.638] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:125: available_completion_tokens: 820
[2024-09-22 23:05:40.638] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:126: tool_use: false
[2024-09-22 23:05:40.639] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:1709: available_completion_tokens: 820, max_tokens from request: 1024, n_predict: 1024
[2024-09-22 23:05:40.639] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:1719: update n_predict from 1024 to 820
[2024-09-22 23:05:40.639] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2327: Update the model metadata.
[2024-09-22 23:05:40.643] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2201: Set prompt to the chat model named Qwen1.5-1.8B-Chat-Q5_K_M.
[2024-09-22 23:05:40.643] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ctx      = 4096
[2024-09-22 23:05:40.643] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_batch    = 4096
[2024-09-22 23:05:40.643] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ubatch   = 4096
[2024-09-22 23:05:40.643] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: flash_attn = 0
[2024-09-22 23:05:40.643] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_base  = 10000.0
[2024-09-22 23:05:40.643] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_scale = 1
[2024-09-22 23:05:40.827] [info] [WASI-NN] llama.cpp: llama_kv_cache_init:        CPU KV buffer size =   768.00 MiB
[2024-09-22 23:05:40.827] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: KV self size  =  768.00 MiB, K (f16):  384.00 MiB, V (f16):  384.00 MiB
[2024-09-22 23:05:40.827] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU  output buffer size =     0.58 MiB
[2024-09-22 23:05:40.828] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU compute buffer size =  2406.00 MiB
[2024-09-22 23:05:40.829] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph nodes  = 846
[2024-09-22 23:05:40.829] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph splits = 1
[2024-09-22 23:05:40.836] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:193: End of the chat completion stream.
[2024-09-22 23:05:40.837] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:461: finish chat completions in stream mode
[2024-09-22 23:05:40.837] [info] rag_api_server::backend::ggml in src/backend/ggml.rs:529: Send the rag query response
[2024-09-22 23:05:40.837] [info] rag_api_server in src/main.rs:515: response_version: HTTP/1.1
[2024-09-22 23:05:40.838] [info] rag_api_server in src/main.rs:517: response_body_size: 0
[2024-09-22 23:05:40.838] [info] rag_api_server in src/main.rs:519: response_status: 200
[2024-09-22 23:05:40.838] [info] rag_api_server in src/main.rs:521: response_is_success: true
[2024-09-22 23:05:40.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:40.840] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ctx      = 4096
[2024-09-22 23:05:40.840] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_batch    = 4096
[2024-09-22 23:05:40.840] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: n_ubatch   = 4096
[2024-09-22 23:05:40.840] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: flash_attn = 0
[2024-09-22 23:05:40.840] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_base  = 10000.0
[2024-09-22 23:05:40.840] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: freq_scale = 1
[2024-09-22 23:05:41.015] [info] [WASI-NN] llama.cpp: llama_kv_cache_init:        CPU KV buffer size =   768.00 MiB
[2024-09-22 23:05:41.015] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: KV self size  =  768.00 MiB, K (f16):  384.00 MiB, V (f16):  384.00 MiB
[2024-09-22 23:05:41.015] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU  output buffer size =     0.58 MiB
[2024-09-22 23:05:41.017] [info] [WASI-NN] llama.cpp: llama_new_context_with_model:        CPU compute buffer size =  2406.00 MiB
[2024-09-22 23:05:41.017] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph nodes  = 846
[2024-09-22 23:05:41.017] [info] [WASI-NN] llama.cpp: llama_new_context_with_model: graph splits = 1
[2024-09-22 23:05:48.935] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:48.936] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:48.936] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:48.937] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:48.937] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:48.939] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:48.939] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"I","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026548,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:48.942] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.049] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.050] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.050] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.050] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.050] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.050] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.050] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" understand","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.050] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.144] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.145] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.145] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.145] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.145] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.145] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" that","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.145] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.251] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" you","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.338] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.339] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.339] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" are","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.339] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.429] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.429] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.429] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.429] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.429] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.430] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.430] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" experiencing","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.430] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.522] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.522] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.522] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.522] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.522] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.522] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.522] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" stress","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.522] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.607] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.607] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.607] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.607] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.607] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.607] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.607] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.607] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.693] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" headaches","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.782] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.782] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.782] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.782] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.782] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.782] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.782] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.782] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.873] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.873] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.873] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.873] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.873] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.873] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.873] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" Stress","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.873] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:49.961] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:49.961] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:49.961] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:49.961] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:49.961] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:49.961] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:49.961] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026549,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:49.961] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:50.055] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:50.055] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:50.055] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:50.055] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:50.055] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:50.055] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:50.055] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" headache","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026550,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:50.056] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:50.146] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:50.146] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:50.146] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:50.146] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:50.146] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:50.146] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:50.146] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" can","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026550,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:50.147] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:50.266] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:50.266] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:50.266] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:50.267] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:50.267] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:50.267] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:50.267] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" be","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026550,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:50.267] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:50.374] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:50.374] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:50.375] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:50.375] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:50.375] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:50.375] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:50.375] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" caused","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026550,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:50.380] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:50.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:50.490] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:50.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:50.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:50.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:50.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:50.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" by","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026550,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:50.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:50.593] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:50.593] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:50.593] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:50.594] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:50.594] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:50.594] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:50.594] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" a","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026550,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:50.594] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:50.709] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:50.709] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:50.709] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:50.709] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:50.709] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:50.710] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:50.710] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" variety","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026550,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:50.710] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:50.876] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:50.876] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:50.876] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:50.876] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:50.876] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:50.876] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:50.876] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" of","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026550,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:50.876] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:50.988] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:50.988] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:50.988] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:50.988] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:50.988] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:50.988] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:50.988] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" factors","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026550,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:50.988] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:51.092] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:51.092] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:51.092] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:51.092] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:51.092] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:51.092] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:51.092] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026551,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:51.092] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:51.197] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:51.197] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:51.197] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:51.197] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:51.197] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:51.198] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:51.198] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" including","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026551,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:51.198] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:51.300] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:51.300] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:51.301] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:51.301] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:51.301] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:51.301] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:51.301] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" physical","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026551,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:51.301] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:51.400] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:51.400] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:51.400] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:51.400] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:51.400] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:51.400] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:51.400] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" activity","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026551,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:51.400] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:51.503] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:51.503] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:51.503] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:51.503] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:51.503] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:51.503] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:51.503] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026551,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:51.503] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:51.608] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:51.608] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:51.608] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:51.608] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:51.608] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:51.608] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:51.608] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" nutrition","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026551,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:51.609] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:51.706] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:51.706] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:51.706] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:51.706] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:51.706] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:51.706] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:51.706] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026551,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:51.706] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:51.803] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:51.803] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:51.803] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:51.803] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:51.803] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:51.803] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:51.803] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" sleep","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026551,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:51.803] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:51.890] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:51.890] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:51.890] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:51.890] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:51.891] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:51.891] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:51.891] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026551,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:51.891] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:51.977] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:51.977] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:51.977] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:51.977] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:51.977] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:51.977] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:51.977] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" work","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026551,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:51.978] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:52.070] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:52.070] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:52.070] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:52.070] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:52.070] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:52.071] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:52.071] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026552,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:52.073] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:52.175] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:52.175] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:52.175] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:52.175] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:52.175] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:52.175] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:52.175] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" emotional","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026552,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:52.175] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:52.268] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:52.268] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:52.268] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:52.268] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:52.268] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:52.268] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:52.269] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" stress","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026552,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:52.269] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:52.358] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:52.358] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:52.358] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:52.358] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:52.358] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:52.358] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:52.358] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026552,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:52.359] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:52.453] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:52.453] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:52.453] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:52.453] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:52.453] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:52.453] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:52.453] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026552,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:52.453] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:52.546] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:52.546] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:52.546] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:52.546] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:52.546] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:52.547] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:52.547] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" other","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026552,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:52.547] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:52.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:52.650] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:52.651] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:52.651] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:52.651] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:52.651] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:52.651] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" underlying","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026552,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:52.651] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:52.739] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:52.740] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:52.740] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:52.740] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:52.740] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:52.740] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:52.740] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" health","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026552,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:52.741] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:52.831] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:52.831] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:52.831] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:52.831] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:52.831] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:52.831] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:52.831] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" conditions","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026552,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:52.831] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:52.919] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:52.919] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:52.919] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:52.919] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:52.919] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:52.920] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:52.920] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".\n\n","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026552,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:52.920] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.005] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.005] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.005] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.005] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.005] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.006] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.006] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"Here","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.006] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.106] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.106] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.106] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.106] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.106] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.106] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.107] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" are","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.107] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.192] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.192] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.192] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.192] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.193] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.193] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.193] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" some","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.193] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.282] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.282] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" strategies","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.372] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.372] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.372] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.372] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.372] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.372] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.372] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" that","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.372] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.460] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.460] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.460] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.460] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.460] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.461] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.461] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" may","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.461] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.553] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.553] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.553] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" help","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.557] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.657] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" reduce","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.743] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" the","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.839] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" symptoms","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:53.933] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:53.933] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:53.933] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:53.933] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:53.934] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:53.934] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:53.934] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" of","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026553,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:53.934] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.025] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.025] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.026] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.026] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.026] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.026] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.026] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" stress","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.026] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.113] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.113] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.113] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.113] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.113] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.114] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.114] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.114] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.203] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" headaches","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.295] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.295] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.295] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.295] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.295] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.295] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.295] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":":\n\n","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.295] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.382] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"1","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.472] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.472] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.472] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.472] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.472] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.472] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.472] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.473] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.563] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.563] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.563] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.563] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.563] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.564] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.564] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" Practice","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.564] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.661] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" relaxation","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.747] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.748] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.748] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.748] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.748] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.748] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.748] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" techniques","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.748] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.836] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.836] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.836] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.836] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.836] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.836] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.836] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":":","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.836] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:54.927] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:54.927] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:54.927] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:54.927] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:54.927] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:54.927] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:54.927] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" Deep","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026554,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:54.927] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.012] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.012] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.013] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.013] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.013] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.013] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.013] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" breathing","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.013] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.120] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.120] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.121] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.121] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.121] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.121] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.121] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" exercises","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.121] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.210] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.210] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.210] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.210] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.210] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.211] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.211] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.211] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.304] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.304] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.305] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.305] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.305] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.305] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.305] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" meditation","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.305] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.391] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.391] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.391] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.391] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.391] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.392] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.392] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.392] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.483] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.483] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.483] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.483] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.483] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.483] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.484] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" yoga","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.484] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.577] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.577] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.577] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.577] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.577] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.577] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.577] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.577] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.665] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.665] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.666] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.666] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.666] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.666] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.666] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" tai","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.666] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.753] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.753] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.753] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.753] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.753] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.753] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.753] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" chi","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.753] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.850] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.850] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.850] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.850] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.850] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.850] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.851] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.851] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:55.946] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:55.946] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:55.946] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:55.946] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:55.946] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:55.946] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:55.946] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026555,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:55.948] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:56.078] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:56.079] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:56.079] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:56.079] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:56.079] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:56.079] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:56.079] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" progressive","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026556,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:56.079] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:56.186] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:56.187] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:56.187] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:56.187] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:56.187] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:56.187] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:56.187] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" muscle","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026556,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:56.187] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:56.286] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:56.286] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:56.286] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:56.286] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:56.286] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:56.286] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:56.286] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" relaxation","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026556,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:56.286] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:56.389] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:56.389] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:56.389] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:56.389] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:56.389] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:56.390] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:56.390] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" are","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026556,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:56.390] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:56.494] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:56.494] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:56.494] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:56.494] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:56.494] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:56.494] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:56.494] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" all","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026556,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:56.494] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:56.602] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:56.602] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:56.602] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:56.602] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:56.602] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:56.603] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:56.603] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" effective","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026556,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:56.603] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:56.711] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:56.711] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:56.711] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:56.711] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:56.711] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:56.711] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:56.711] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" ways","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026556,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:56.711] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:56.824] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:56.824] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:56.824] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:56.824] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:56.824] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:56.824] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:56.824] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" to","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026556,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:56.824] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:56.926] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:56.926] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:56.926] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:56.926] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:56.926] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:56.926] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:56.926] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" reduce","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026556,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:56.926] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.019] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.019] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.019] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.019] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.019] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.019] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.019] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" stress","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.019] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.110] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.110] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.110] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.110] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.110] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.110] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.110] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.111] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.202] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.202] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.202] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.202] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.202] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.202] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.202] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" tension","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.202] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.289] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" in","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.380] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.380] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.380] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.380] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.380] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.380] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.380] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" the","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.415] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.508] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.508] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.508] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.508] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.508] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.508] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.508] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" neck","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.508] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.597] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.597] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.598] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.598] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.598] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.598] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.598] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.602] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.708] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.708] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.709] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.709] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.709] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.709] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.709] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" shoulders","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.709] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.801] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.801] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.801] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.801] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.801] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.801] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.801] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".\n\n","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.801] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.896] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.896] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.896] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.896] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.896] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.897] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.897] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"2","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.897] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:57.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:57.997] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:57.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:57.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:57.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:57.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:57.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026557,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:57.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:58.088] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:58.088] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:58.088] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:58.088] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:58.088] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:58.088] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:58.088] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" Stay","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026558,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:58.089] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:58.196] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:58.196] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:58.196] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:58.196] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:58.196] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:58.197] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:58.197] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" physically","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026558,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:58.197] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:58.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:58.289] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:58.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:58.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:58.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:58.289] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:58.290] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" active","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026558,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:58.290] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:58.385] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:58.385] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:58.385] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:58.385] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:58.385] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:58.386] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:58.386] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":":","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026558,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:58.386] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:58.481] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:58.481] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:58.481] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:58.481] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:58.481] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:58.481] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:58.481] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" Regular","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026558,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:58.482] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:58.579] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:58.579] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:58.579] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:58.579] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:58.579] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:58.580] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:58.580] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" physical","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026558,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:58.580] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:58.677] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:58.678] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:58.678] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:58.678] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:58.678] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:58.678] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:58.678] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" activity","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026558,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:58.679] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:58.770] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:58.770] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:58.770] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:58.770] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:58.770] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:58.770] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:58.770] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" can","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026558,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:58.770] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:58.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:58.862] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:58.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:58.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:58.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:58.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:58.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" help","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026558,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:58.863] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:58.949] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:58.949] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:58.949] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:58.949] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:58.949] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:58.949] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:58.950] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" reduce","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026558,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:58.950] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.043] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.043] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.043] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.043] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.043] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.044] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.044] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" stress","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.044] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.149] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.149] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.149] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.149] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.150] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.150] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.150] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.150] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.240] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.240] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.240] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.240] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.240] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.240] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.241] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" anxiety","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.241] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.332] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.332] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.332] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.332] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.332] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.332] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.333] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" by","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.333] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.428] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.428] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.428] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.428] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.428] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.428] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.428] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" increasing","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.428] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.528] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.529] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.529] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.529] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.529] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.529] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.529] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" end","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.529] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.624] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.624] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.624] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.624] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.624] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.624] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.624] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"orph","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.624] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.719] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.719] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.719] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.719] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.719] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.720] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.720] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"ins","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.720] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.810] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.811] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.811] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.811] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.811] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.811] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.811] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.811] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.902] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.902] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.902] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.902] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.902] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.902] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.902] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" reducing","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.902] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:05:59.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:05:59.997] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:05:59.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:05:59.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:05:59.997] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:05:59.998] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:05:59.998] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" cortisol","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026559,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:05:59.998] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:00.095] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:00.095] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:00.095] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:00.095] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:00.095] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:00.095] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:00.095] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" levels","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026560,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:00.095] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:00.185] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:00.185] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:00.185] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:00.185] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:00.185] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:00.185] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:00.185] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026560,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:00.188] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:00.280] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:00.280] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:00.280] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:00.280] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:00.280] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:00.280] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:00.280] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" improving","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026560,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:00.280] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:00.381] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:00.381] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:00.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:00.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:00.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:00.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:00.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" cardiovascular","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026560,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:00.382] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:00.470] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:00.471] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:00.471] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:00.471] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:00.471] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:00.471] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:00.471] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" health","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026560,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:00.471] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:00.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:00.561] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:00.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:00.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:00.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:00.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:00.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026560,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:00.562] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:00.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:00.650] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:00.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:00.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:00.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:00.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:00.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026560,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:00.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:00.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:00.743] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:00.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:00.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:00.743] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:00.744] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:00.744] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" other","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026560,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:00.744] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:00.841] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:00.841] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:00.841] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:00.841] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:00.841] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:00.841] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:00.841] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" beneficial","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026560,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:00.841] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:00.933] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:00.933] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:00.933] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:00.933] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:00.933] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:00.933] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:00.933] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" effects","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026560,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:00.934] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:01.023] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:01.024] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:01.024] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:01.024] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:01.024] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:01.024] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:01.024] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" on","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026561,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:01.024] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:01.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:01.144] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:01.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:01.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:01.144] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:01.145] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:01.145] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" mental","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026561,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:01.145] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:01.271] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:01.271] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:01.272] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:01.272] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:01.272] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:01.272] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:01.272] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" health","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026561,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:01.272] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:01.373] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:01.373] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:01.373] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:01.373] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:01.373] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:01.373] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:01.373] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026561,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:01.373] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:01.479] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:01.479] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:01.479] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:01.479] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:01.479] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:01.480] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:01.480] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" overall","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026561,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:01.480] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:01.588] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:01.588] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:01.588] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:01.588] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:01.588] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:01.588] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:01.589] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" well","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026561,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:01.589] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:01.692] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:01.693] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:01.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:01.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:01.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:01.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:01.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"-being","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026561,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:01.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:01.794] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:01.794] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:01.794] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:01.794] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:01.794] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:01.795] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:01.795] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".\n\n","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026561,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:01.796] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:01.901] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:01.901] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:01.901] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:01.901] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:01.901] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:01.901] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:01.901] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"3","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026561,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:01.901] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.005] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.005] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.005] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.005] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.005] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.006] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.006] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.006] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.110] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.110] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.110] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.110] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.111] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.111] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.111] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" Maintain","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.111] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.202] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.203] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" a","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.203] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.294] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.294] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.294] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.294] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.294] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.294] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.294] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" healthy","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.294] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.392] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.392] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.392] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.392] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.392] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.392] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.392] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" diet","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.393] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.484] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.484] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.484] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":":","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.583] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" A","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.584] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.673] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.673] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.673] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.673] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.673] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.673] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.674] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" balanced","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.674] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.764] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.764] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.764] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.764] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.764] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.764] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.764] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" diet","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.766] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.863] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.863] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.863] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.863] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.863] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.863] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.863] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" rich","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.863] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:02.954] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:02.954] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:02.954] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:02.954] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:02.954] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:02.955] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:02.955] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" in","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026562,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:02.955] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:03.058] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:03.058] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:03.058] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:03.058] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:03.058] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:03.058] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:03.058] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" nutrients","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026563,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:03.058] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:03.158] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:03.158] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:03.158] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:03.158] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:03.158] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:03.158] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:03.158] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" such","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026563,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:03.158] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:03.261] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:03.261] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:03.261] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:03.261] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:03.261] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:03.261] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:03.261] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" as","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026563,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:03.261] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:03.367] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:03.367] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:03.367] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:03.367] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:03.367] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:03.367] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:03.368] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" vitamins","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026563,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:03.368] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:03.463] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:03.464] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:03.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:03.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:03.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:03.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:03.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" C","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026563,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:03.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:03.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:03.554] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:03.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:03.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:03.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:03.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:03.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026563,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:03.554] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:03.653] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:03.653] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:03.653] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:03.653] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:03.653] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:03.653] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:03.653] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" E","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026563,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:03.653] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:03.742] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:03.742] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:03.742] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:03.742] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:03.742] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:03.742] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:03.742] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026563,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:03.742] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:03.833] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:03.833] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:03.833] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:03.833] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:03.833] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:03.833] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:03.833] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" B","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026563,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:03.833] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:03.922] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:03.922] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:03.932] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:03.932] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:03.932] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:03.932] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:03.932] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"6","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026563,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:03.932] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.024] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.024] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.025] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.025] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.025] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.025] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.025] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.025] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.117] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.117] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.117] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.117] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.117] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.118] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.118] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" B","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.118] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.220] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.220] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.220] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.220] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.220] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.220] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.220] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"1","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.221] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.309] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.309] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.309] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.309] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.310] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.310] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.310] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"2","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.312] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.408] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.408] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.408] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.408] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.408] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.408] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.408] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.408] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.495] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.495] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.495] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.495] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.495] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.496] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.496] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" iron","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.496] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.585] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.585] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.585] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.586] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.586] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.586] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.586] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.586] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.678] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.678] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.678] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.678] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.678] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.679] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.679] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" calcium","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.679] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.767] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.768] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.768] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.768] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.768] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.768] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.768] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.768] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.861] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.861] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.861] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.861] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.861] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.861] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.861] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" magnesium","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.861] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:04.957] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:04.957] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:04.957] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:04.957] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:04.957] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:04.958] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:04.958] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026564,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:04.958] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:05.052] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:05.053] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:05.053] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:05.053] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:05.053] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:05.053] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:05.053] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" protein","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026565,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:05.053] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:05.140] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:05.141] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:05.141] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:05.141] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:05.141] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:05.141] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:05.141] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026565,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:05.141] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:05.238] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:05.238] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:05.238] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:05.238] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:05.238] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:05.239] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:05.239] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" fiber","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026565,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:05.239] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:05.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:05.338] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:05.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:05.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:05.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:05.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:05.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026565,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:05.338] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:05.435] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:05.435] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:05.436] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:05.436] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:05.436] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:05.436] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:05.436] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" antioxidants","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026565,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:05.436] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:05.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:05.523] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:05.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:05.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:05.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:05.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:05.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026565,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:05.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:05.623] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:05.623] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:05.623] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:05.623] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:05.623] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:05.623] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:05.624] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026565,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:05.624] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:05.718] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:05.718] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:05.718] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:05.718] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:05.718] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:05.718] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:05.718] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" omega","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026565,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:05.719] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:05.809] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:05.810] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:05.810] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:05.811] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:05.811] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:05.811] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:05.811] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"-","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026565,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:05.813] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:05.905] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:05.905] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:05.905] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:05.905] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:05.905] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:05.905] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:05.905] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"3","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026565,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:05.905] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:06.000] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:06.001] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:06.001] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:06.001] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:06.001] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:06.002] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:06.002] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" fatty","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026566,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:06.002] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:06.096] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:06.097] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:06.097] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:06.097] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:06.097] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:06.097] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:06.097] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" acids","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026566,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:06.097] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:06.198] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:06.198] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:06.198] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:06.198] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:06.198] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:06.198] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:06.198] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" can","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026566,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:06.199] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:06.308] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:06.308] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:06.308] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:06.308] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:06.308] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:06.309] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:06.309] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" help","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026566,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:06.309] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:06.438] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:06.438] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:06.438] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:06.438] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:06.438] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:06.438] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:06.439] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" reduce","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026566,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:06.439] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:06.544] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:06.544] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:06.544] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:06.544] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:06.544] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:06.544] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:06.544] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" stress","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026566,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:06.544] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:06.649] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:06.650] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:06.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:06.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:06.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:06.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:06.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026566,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:06.650] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:06.754] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:06.754] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:06.755] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:06.755] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:06.755] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:06.755] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:06.755] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" tension","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026566,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:06.756] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:06.859] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:06.859] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:06.859] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:06.860] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:06.860] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:06.860] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:06.860] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" in","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026566,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:06.860] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:06.967] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:06.967] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:06.967] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:06.967] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:06.967] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:06.967] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:06.967] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" the","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026566,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:06.970] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:07.077] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:07.077] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:07.077] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:07.077] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:07.077] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:07.077] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:07.077] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" neck","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026567,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:07.077] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:07.177] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:07.177] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:07.178] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:07.178] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:07.178] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:07.178] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:07.178] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026567,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:07.178] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:07.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:07.283] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:07.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:07.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:07.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:07.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:07.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" shoulders","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026567,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:07.283] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:07.378] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:07.379] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:07.379] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:07.379] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:07.379] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:07.379] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:07.379] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" by","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026567,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:07.379] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:07.489] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:07.489] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:07.489] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:07.489] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:07.489] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:07.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:07.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" supporting","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026567,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:07.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:07.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:07.583] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:07.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:07.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:07.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:07.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:07.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" overall","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026567,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:07.583] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:07.680] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:07.680] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:07.680] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:07.680] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:07.680] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:07.681] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:07.681] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" health","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026567,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:07.681] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:07.774] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:07.774] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:07.774] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:07.774] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:07.774] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:07.774] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:07.774] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026567,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:07.774] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:07.861] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:07.862] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:07.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:07.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:07.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:07.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:07.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" wellness","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026567,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:07.862] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:07.955] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:07.955] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:07.955] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:07.955] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:07.955] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:07.955] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:07.955] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".\n\n","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026567,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:07.955] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.054] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.054] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.054] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.054] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.054] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.054] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.054] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"4","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.054] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.142] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.142] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.142] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.142] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.142] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.142] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.142] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.142] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.232] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.232] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.232] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.232] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.232] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.232] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.232] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" Get","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.233] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.326] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.327] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.327] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" adequate","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.327] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.416] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.416] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.416] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.416] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.416] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.416] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.416] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" sleep","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.416] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.511] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.511] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.511] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.511] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.511] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.511] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.511] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":":","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.513] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.606] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.606] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.606] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.606] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.606] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.607] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.607] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" Getting","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.607] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.698] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.698] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.698] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.698] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.698] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.698] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.698] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" sufficient","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.698] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.788] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.788] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.788] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.788] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.788] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.788] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.788] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" sleep","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.788] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.880] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.880] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.880] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.881] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.881] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.881] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.881] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" is","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.881] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:08.982] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:08.982] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:08.982] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:08.982] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:08.982] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:08.982] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:08.982] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" critical","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026568,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:08.982] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:09.081] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:09.081] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:09.081] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:09.081] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:09.081] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:09.081] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:09.081] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" for","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026569,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:09.081] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:09.181] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:09.181] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:09.181] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:09.181] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:09.181] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:09.181] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:09.181] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" reducing","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026569,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:09.181] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:09.281] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:09.281] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:09.281] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:09.281] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:09.281] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:09.282] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:09.282] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" stress","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026569,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:09.282] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:09.376] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:09.376] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:09.376] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:09.376] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:09.376] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:09.376] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:09.376] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026569,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:09.376] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:09.475] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:09.475] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:09.475] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:09.475] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:09.475] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:09.475] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:09.475] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" tension","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026569,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:09.475] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:09.569] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:09.569] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:09.569] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:09.569] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:09.569] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:09.570] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:09.570] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" in","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026569,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:09.570] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:09.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:09.661] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:09.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:09.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:09.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:09.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:09.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" the","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026569,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:09.661] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:09.755] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:09.755] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:09.755] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:09.755] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:09.755] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:09.756] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:09.756] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" neck","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026569,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:09.756] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:09.848] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:09.848] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:09.848] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:09.848] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:09.848] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:09.849] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:09.849] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026569,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:09.849] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:09.940] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:09.940] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:09.940] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:09.940] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:09.941] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:09.941] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:09.941] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" shoulders","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026569,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:09.941] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:10.033] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:10.033] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:10.033] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:10.034] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:10.034] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:10.034] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:10.034] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" by","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026570,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:10.036] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:10.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:10.132] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:10.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:10.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:10.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:10.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:10.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" promoting","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026570,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:10.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:10.230] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:10.230] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:10.230] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:10.230] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:10.230] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:10.231] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:10.231] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" relaxation","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026570,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:10.231] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:10.329] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:10.329] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:10.329] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:10.329] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:10.329] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:10.329] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:10.329] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026570,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:10.329] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:10.420] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:10.420] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:10.420] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:10.421] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:10.421] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:10.421] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:10.421] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" repair","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026570,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:10.421] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:10.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:10.523] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:10.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:10.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:10.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:10.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:10.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" tissue","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026570,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:10.523] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:10.630] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:10.630] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:10.630] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:10.630] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:10.630] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:10.631] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:10.631] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" damage","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026570,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:10.631] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:10.734] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:10.734] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:10.734] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:10.734] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:10.734] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:10.734] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:10.734] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026570,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:10.734] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:10.838] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:10.838] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:10.838] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:10.838] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:10.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:10.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:10.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" boost","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026570,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:10.839] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:10.930] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:10.930] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:10.930] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:10.930] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:10.930] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:10.930] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:10.930] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" immune","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026570,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:10.930] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:11.022] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:11.022] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:11.022] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:11.022] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:11.023] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:11.023] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:11.023] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" function","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026571,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:11.023] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:11.119] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:11.119] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:11.119] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:11.119] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:11.119] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:11.119] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:11.119] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026571,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:11.121] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:11.241] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:11.241] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:11.241] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:11.241] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:11.241] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:11.241] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:11.241] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" improve","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026571,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:11.241] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:11.346] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:11.346] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:11.346] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:11.346] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:11.346] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:11.346] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:11.346] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" cardiovascular","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026571,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:11.346] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:11.439] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:11.439] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:11.439] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:11.439] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:11.439] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:11.440] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:11.440] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" health","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026571,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:11.440] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:11.575] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:11.575] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:11.575] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:11.576] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:11.576] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:11.576] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:11.576] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026571,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:11.576] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:11.690] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:11.690] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:11.690] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:11.690] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:11.690] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:11.690] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:11.690] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026571,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:11.690] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:11.797] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:11.797] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:11.797] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:11.797] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:11.797] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:11.797] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:11.797] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" other","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026571,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:11.797] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:11.907] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:11.907] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:11.907] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:11.907] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:11.907] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:11.907] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:11.907] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" beneficial","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026571,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:11.907] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:12.014] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:12.014] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:12.014] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:12.014] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:12.014] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:12.014] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:12.014] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" effects","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026572,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:12.014] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:12.116] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:12.116] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:12.116] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:12.116] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:12.117] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:12.117] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:12.117] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" on","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026572,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:12.117] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:12.219] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:12.219] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:12.219] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:12.219] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:12.219] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:12.219] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:12.219] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" mental","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026572,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:12.219] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:12.325] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:12.325] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:12.325] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:12.325] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:12.325] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:12.325] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:12.325] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" health","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026572,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:12.325] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:12.432] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:12.432] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:12.432] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:12.432] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:12.432] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:12.432] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:12.432] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026572,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:12.432] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:12.544] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:12.545] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:12.545] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:12.545] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:12.545] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:12.545] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:12.545] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" overall","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026572,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:12.545] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:12.651] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:12.651] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:12.652] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:12.652] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:12.652] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:12.652] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:12.652] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" well","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026572,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:12.652] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:12.746] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:12.746] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:12.746] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:12.746] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:12.746] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:12.746] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:12.746] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"-being","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026572,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:12.746] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:12.842] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:12.842] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:12.842] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:12.842] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:12.842] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:12.842] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:12.842] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".\n\n","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026572,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:12.844] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:12.956] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:12.956] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:12.956] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:12.957] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:12.957] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:12.957] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:12.957] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":"In","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026572,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:12.957] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:13.049] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:13.049] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:13.049] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:13.049] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:13.049] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:13.050] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:13.050] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" conclusion","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026573,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:13.050] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:13.149] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:13.149] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:13.149] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:13.149] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:13.149] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:13.149] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:13.149] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026573,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:13.149] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:13.243] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:13.243] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:13.243] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:13.243] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:13.244] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:13.244] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:13.244] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" there","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026573,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:13.244] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:13.339] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:13.339] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:13.339] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:13.339] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:13.339] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:13.340] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:13.340] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" are","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026573,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:13.340] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:13.450] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:13.451] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:13.451] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:13.451] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:13.451] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:13.451] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:13.451] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" several","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026573,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:13.451] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:13.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:13.561] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:13.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:13.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:13.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:13.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:13.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" strategies","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026573,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:13.561] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:13.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:13.657] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:13.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:13.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:13.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:13.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:13.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" that","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026573,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:13.657] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:13.749] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:13.749] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:13.749] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:13.749] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:13.749] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:13.749] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:13.749] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" may","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026573,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:13.749] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:13.843] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:13.843] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:13.843] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:13.843] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:13.843] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:13.843] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:13.843] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" help","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026573,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:13.843] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:13.967] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:13.967] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:13.967] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:13.967] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:13.967] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:13.968] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:13.968] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" reduce","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026573,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:13.968] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:14.062] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:14.062] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:14.062] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:14.062] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:14.062] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:14.062] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:14.062] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" the","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026574,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:14.062] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:14.164] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:14.165] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:14.165] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:14.165] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:14.165] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:14.165] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:14.165] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" symptoms","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026574,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:14.165] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:14.260] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:14.260] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:14.260] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:14.260] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:14.260] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:14.261] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:14.261] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" of","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026574,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:14.261] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:14.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:14.363] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:14.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:14.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:14.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:14.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:14.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" stress","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026574,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:14.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:14.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:14.464] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:14.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:14.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:14.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:14.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:14.464] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026574,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:14.466] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:14.558] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:14.558] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:14.558] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:14.558] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:14.558] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:14.559] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:14.559] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" headaches","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026574,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:14.559] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:14.648] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:14.648] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:14.648] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:14.648] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:14.648] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:14.648] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:14.648] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026574,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:14.648] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:14.754] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:14.754] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:14.754] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:14.754] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:14.754] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:14.754] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:14.754] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" By","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026574,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:14.754] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:14.849] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:14.849] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:14.849] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:14.849] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:14.850] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:14.850] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:14.850] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" practicing","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026574,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:14.850] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:14.942] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:14.942] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:14.942] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:14.942] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:14.942] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:14.942] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:14.942] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" these","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026574,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:14.943] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.035] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.036] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.036] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.036] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.036] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.036] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.036] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" strategies","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.036] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.132] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" consistently","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.132] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.226] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.226] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.226] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.226] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.226] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.227] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.227] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.227] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.326] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" you","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.326] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.430] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.430] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.430] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.430] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.430] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.431] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.431] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" can","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.433] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.518] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.518] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.518] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.518] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.518] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.518] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.518] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" help","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.519] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.598] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.598] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.598] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.598] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.598] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.599] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.599] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" promote","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.599] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.691] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.691] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.691] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.691] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.691] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.691] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.691] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" overall","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.691] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.784] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.785] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.785] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.785] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.785] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.785] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.785] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" health","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.785] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.879] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.879] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.879] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.879] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.879] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.879] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.879] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.879] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:15.972] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:15.972] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:15.972] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:15.972] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:15.972] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:15.972] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:15.972] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" wellness","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026575,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:15.973] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:16.063] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:16.063] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:16.063] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:16.063] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:16.063] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:16.063] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:16.063] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":",","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026576,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:16.063] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:16.159] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:16.159] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:16.159] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:16.159] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:16.159] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:16.159] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:16.159] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" which","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026576,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:16.159] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:16.266] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:16.266] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:16.266] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:16.266] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:16.266] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:16.266] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:16.266] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" in","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026576,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:16.267] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:16.362] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:16.362] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:16.362] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:16.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:16.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:16.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:16.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" turn","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026576,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:16.363] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:16.462] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:16.462] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:16.462] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:16.462] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:16.462] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:16.462] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:16.462] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" can","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026576,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:16.462] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:16.565] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:16.565] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:16.565] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:16.565] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:16.565] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:16.566] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:16.566] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" help","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026576,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:16.566] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:16.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:16.693] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:16.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:16.693] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:16.694] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:16.694] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:16.694] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" reduce","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026576,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:16.694] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:16.805] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:16.805] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:16.805] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:16.805] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:16.805] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:16.806] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:16.806] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" the","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026576,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:16.806] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:16.920] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:16.920] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:16.920] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:16.920] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:16.920] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:16.921] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:16.921] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" symptoms","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026576,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:16.921] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:17.021] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:17.021] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:17.021] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:17.022] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:17.022] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:17.022] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:17.022] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" of","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026577,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:17.024] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:17.137] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:17.137] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:17.137] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:17.137] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:17.137] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:17.137] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:17.138] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" stress","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026577,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:17.138] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:17.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:17.251] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:17.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:17.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:17.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:17.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:17.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" and","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026577,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:17.251] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:17.361] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:17.361] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:17.361] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:17.361] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:17.361] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:17.361] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:17.361] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":" headaches","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026577,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:17.361] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:17.478] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2718: Compute the chat stream chunk successfully.
[2024-09-22 23:06:17.478] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:198: Get output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M in the stream mode.
[2024-09-22 23:06:17.478] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2724: retrieved the output buffer
[2024-09-22 23:06:17.478] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2775: decoded the output buffer
[2024-09-22 23:06:17.478] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2809: created chat completion chunk
[2024-09-22 23:06:17.478] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:17.478] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[{"index":0,"delta":{"content":".","role":"assistant"},"logprobs":null,"finish_reason":null}],"created":1727026577,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk"}


[2024-09-22 23:06:17.478] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:17.481] [info] [WASI-NN] GGML backend: EOS token found
[2024-09-22 23:06:17.482] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:243: Get token info from the model named Qwen1.5-1.8B-Chat-Q5_K_M.
[2024-09-22 23:06:17.482] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:169: Get the output buffer generated by the model named Qwen1.5-1.8B-Chat-Q5_K_M
[2024-09-22 23:06:17.482] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:187: Output buffer size: 99
[2024-09-22 23:06:17.482] [info] llama_core::utils in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/utils.rs:282: prompt tokens: 212, completion tokens: 292
[2024-09-22 23:06:17.482] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2845: token_info: 212 prompt tokens, 292 completion tokens
[2024-09-22 23:06:17.483] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:17.483] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: {"id":"9b619fe5-3a49-43fc-a8c4-6d939262f99f","choices":[],"created":1727026577,"model":"Qwen1.5-1.8B-Chat-Q5_K_M","system_fingerprint":"fp_44709d6fcb","object":"chat.completion.chunk","usage":{"prompt_tokens":212,"completion_tokens":292,"total_tokens":504}}


[2024-09-22 23:06:17.483] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:17.485] [info] [WASI-NN] GGML backend: EOS token found
[2024-09-22 23:06:17.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:4267: Return the chat stream chunk!
[2024-09-22 23:06:17.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: data: [DONE]


[2024-09-22 23:06:17.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2675: Compute the chat stream chunk.
[2024-09-22 23:06:17.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2682: Return the chat stream chunk!
[2024-09-22 23:06:17.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2639: next item: [GGML] End of sequence
[2024-09-22 23:06:17.485] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2465: Clean up the context of the stream work environment.
[2024-09-22 23:06:17.486] [info] [WASI-NN] llama.cpp: 
[2024-09-22 23:06:17.486] [info] [WASI-NN] llama.cpp: llama_print_timings:        load time =   81784.76 ms
[2024-09-22 23:06:17.486] [info] [WASI-NN] llama.cpp: llama_print_timings:      sample time =     249.01 ms /   293 runs   (    0.85 ms per token,  1176.65 tokens per second)
[2024-09-22 23:06:17.486] [info] [WASI-NN] llama.cpp: llama_print_timings: prompt eval time =    7784.50 ms /   212 tokens (   36.72 ms per token,    27.23 tokens per second)
[2024-09-22 23:06:17.486] [info] [WASI-NN] llama.cpp: llama_print_timings:        eval time =   28125.08 ms /   291 runs   (   96.65 ms per token,    10.35 tokens per second)
[2024-09-22 23:06:17.486] [info] [WASI-NN] llama.cpp: llama_print_timings:       total time =  110469.42 ms /   503 tokens
[2024-09-22 23:06:17.490] [info] llama_core::chat in /home/runner/.cargo/git/checkouts/llamaedge-4f9ea6368fc01861/6a4103b/crates/llama-core/src/chat.rs:2617: Cleanup done!
